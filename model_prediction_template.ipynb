{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.1\n"
     ]
    }
   ],
   "source": [
    "# get version of python\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.1\n"
     ]
    }
   ],
   "source": [
    "# install latest version of scikit-learn\n",
    "# ---------------------------------------\n",
    "# ! pip install scikit-learn==0.24.1\n",
    "# https://scikit-learn.org/stable/\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Proyect 2__\n",
    "# Model delivery Template\n",
    "## Use this template to test your persisted model. \n",
    "\n",
    "### This will ensure that we can __grade it correctly__ an the model is able to __execute__ without errors.\n",
    "### Please note that:\n",
    "- `load_data()` function should load data in your computer. During the grading process it will be re-defined to load a __test dataset__.\n",
    "- `load_model()` will not be modified and you should include all custom transformers that you have defined. Otherwise the model will raise an error.\n",
    "- Your model has to be persisted using the following structur: `name_lastname.pkl`\n",
    "- Make sure that the code that you submit in this template is able to predict correctly once provided with data ->  `model.predict(data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your required imports here:\n",
    "# ------------------------------------------------------------------------\n",
    "import joblib \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data definition here:\n",
    "# ------------------------------------------------------------------------\n",
    "def load_data(filename):\n",
    "    \"\"\" Load dataset from filename\n",
    "    Args:\n",
    "        filename (string): Path to data\n",
    "        \n",
    "    Returns:\n",
    "        df (DataFrame): Dataset from file\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom defined transformers here:\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# define column indexes\n",
    "horsepower_idx, engine_size_idx, length_idx, width_idx, height_idx, curb_weight_idx = 0,1,2,3,4,5\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class CombineAttributes(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Custom transformer. Adds horsepower to weight ratio\n",
    "        and optionaly the volume of the car.\n",
    "\n",
    "    Args:\n",
    "        add_volume (bool): Add volume to the dataset\n",
    "\n",
    "    Returns:\n",
    "        array with original and added features.\n",
    "    \"\"\"\n",
    "    # constructor\n",
    "    def __init__(self, add_volume=False):\n",
    "        self.add_volume = add_volume\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        hp_to_weight_ratio = X[:,horsepower_idx]/X[:,curb_weight_idx]\n",
    "\n",
    "        if self.add_volume:\n",
    "            volume = X[:,length_idx]*X[:,width_idx]*X[:,height_idx]\n",
    "            return np.c_[X, hp_to_weight_ratio, volume]\n",
    "\n",
    "        else:\n",
    "            return np.c_[X, hp_to_weight_ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model funtion here:\n",
    "# --------------------------------------------------------------------------------------------------------        \n",
    "def load_model(filename=\"juan_elgueta.pkl\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # load from disk\n",
    "    my_model_loaded = joblib.load(filename)\n",
    "    \n",
    "    return my_model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# test that your model can predict values here:\n",
    "# --------------------------------------------------------------------------------------------------------        \n",
    "path = './data/'\n",
    "filename = 'proyect_2_dataset.csv'\n",
    "df = load_data(path+filename)\n",
    "\n",
    "model = load_model(\"classification_model.pkl\")\n",
    "\n",
    "# predict\n",
    "print(model.predict(df[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
